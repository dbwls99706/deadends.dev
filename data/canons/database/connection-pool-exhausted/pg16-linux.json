{
  "schema_version": "1.0.0",
  "id": "database/connection-pool-exhausted/pg16-linux",
  "url": "https://deadends.dev/database/connection-pool-exhausted/pg16-linux",
  "error": {
    "signature": "sqlalchemy.exc.TimeoutError: QueuePool limit of size 5 overflow 10 reached, connection timed out, timeout 30.00",
    "regex": "QueuePool limit.*reached|connection pool exhausted|pool.*timeout|ConnectionPoolExhausted|unable to acquire.*connection from pool",
    "domain": "database",
    "category": "resource_error",
    "first_seen": "2023-01-01",
    "last_confirmed": "2026-02-12"
  },
  "environment": {
    "runtime": {
      "name": "postgresql",
      "version_range": ">=16,<17"
    },
    "os": "linux"
  },
  "verdict": {
    "resolvable": "true",
    "fix_success_rate": 0.9,
    "confidence": 0.92,
    "last_updated": "2026-02-12",
    "summary": "The application-level connection pool has no available connections. All pool connections are checked out and in use (or leaked). This is different from PostgreSQL's max_connections limit; it is the application pool's own limit. Caused by connection leaks, slow queries holding connections, or undersized pool."
  },
  "dead_ends": [
    {
      "action": "Setting the pool size extremely high without fixing the underlying leak",
      "why_fails": "A larger pool masks the leak temporarily but eventually the pool fills up again and the error returns. Meanwhile, the large number of open connections may hit PostgreSQL's max_connections limit, creating a new error.",
      "fail_rate": 0.8,
      "sources": [
        "https://www.postgresql.org/docs/current/libpq-connect.html"
      ],
      "condition": ""
    },
    {
      "action": "Disabling connection pooling entirely and opening new connections per request",
      "why_fails": "Opening a new PostgreSQL connection takes 100-200ms due to process forking and authentication. Without pooling, performance degrades severely under load, and you risk hitting PostgreSQL's max_connections limit directly.",
      "fail_rate": 0.75,
      "sources": [
        "https://www.postgresql.org/docs/current/libpq-connect.html"
      ],
      "condition": ""
    }
  ],
  "workarounds": [
    {
      "action": "Fix connection leaks by ensuring all connections are returned to the pool",
      "success_rate": 0.92,
      "how": "In SQLAlchemy, always use 'with engine.connect() as conn:' or scoped sessions that are properly closed. Enable pool_pre_ping=True to detect stale connections. Set pool_recycle=3600 to recycle connections periodically. Log pool checkout events to identify code paths that never return connections.",
      "sources": [],
      "condition": ""
    },
    {
      "action": "Tune pool size and timeout parameters based on actual workload",
      "success_rate": 0.87,
      "how": "Set pool_size to match the expected concurrent database operations (not total requests). In SQLAlchemy: create_engine(url, pool_size=20, max_overflow=10, pool_timeout=30). Monitor pool usage with pool.status(). Rule of thumb: pool_size should be slightly above the average concurrent query count.",
      "sources": [],
      "condition": ""
    }
  ],
  "transition_graph": {
    "leads_to": [
      {
        "error_id": "database/too-many-connections/pg16-linux",
        "probability": 0.25,
        "condition": "when increasing pool size or opening direct connections pushes past PostgreSQL max_connections"
      },
      {
        "error_id": "database/query-timeout/pg16-linux",
        "probability": 0.2,
        "condition": "when pool exhaustion causes queued requests to timeout waiting for a connection"
      }
    ],
    "preceded_by": [
      {
        "error_id": "database/query-timeout/pg16-linux",
        "probability": 0.25,
        "condition": "when slow queries hold connections for too long, preventing them from being returned to the pool"
      },
      {
        "error_id": "database/deadlock-detected/pg16-linux",
        "probability": 0.15,
        "condition": "when deadlocked transactions hold pool connections indefinitely"
      }
    ],
    "frequently_confused_with": [
      {
        "error_id": "database/too-many-connections/pg16-linux",
        "distinction": "Connection pool exhausted is an application-level limit (SQLAlchemy QueuePool, HikariCP, etc.). Too many connections is a PostgreSQL server-level limit (max_connections). The pool error happens before reaching PostgreSQL's limit. Pool errors show library-specific messages; server errors show PostgreSQL FATAL messages."
      }
    ]
  },
  "metadata": {
    "generated_by": "bulk_generate.py",
    "generation_date": "2026-02-12",
    "review_status": "auto_generated",
    "evidence_count": 65,
    "last_verification": "2026-02-12"
  }
}
