{
  "schema_version": "1.0.0",
  "id": "database/elasticsearch-index-read-only/es8-linux",
  "url": "https://deadends.dev/database/elasticsearch-index-read-only/es8-linux",
  "error": {
    "signature": "ClusterBlockException: index [my_index] blocked by: [FORBIDDEN/12/index read-only / allow delete (api)]",
    "regex": "ClusterBlockException|index.*read.only|FORBIDDEN/12|FORBIDDEN/8|read_only_allow_delete|index.*blocked",
    "domain": "database",
    "category": "cluster_error",
    "first_seen": "2023-01-01",
    "last_confirmed": "2026-02-12"
  },
  "environment": {
    "runtime": {"name": "elasticsearch", "version_range": ">=8.0,<9.0"},
    "os": "linux"
  },
  "verdict": {
    "resolvable": "true",
    "fix_success_rate": 0.92,
    "confidence": 0.94,
    "last_updated": "2026-02-12",
    "summary": "Elasticsearch automatically set the index to read-only mode. This is most commonly triggered by the disk-based shard allocator when disk usage exceeds the flood_stage watermark (default 95%). Elasticsearch protects itself from filling the disk completely by blocking writes to indices on the affected node. It can also occur when an administrator manually set the index to read-only, or during a cluster recovery after a node failure."
  },
  "dead_ends": [
    {
      "action": "Repeatedly removing the read-only block without addressing disk space",
      "why_fails": "If disk usage is still above the flood_stage watermark, Elasticsearch will immediately re-apply the read-only block after it is removed. The block is a protective mechanism; removing it without freeing disk space results in an infinite loop of blocking and unblocking.",
      "fail_rate": 0.90,
      "sources": [],
      "condition": ""
    },
    {
      "action": "Deleting the index and recreating it to remove the block",
      "why_fails": "Deleting the index removes all data permanently. The new index may also become read-only immediately if disk space is still insufficient. This destroys data without solving the root cause.",
      "fail_rate": 0.85,
      "sources": [],
      "condition": ""
    }
  ],
  "workarounds": [
    {
      "action": "Free disk space and then remove the read-only block",
      "success_rate": 0.95,
      "how": "First, free disk space: delete old indices (DELETE /old-index-2024*), use ILM to roll over indices, clean up snapshots, or add disk capacity. Get disk below 90% usage. Then remove the block: PUT /my_index/_settings {\"index.blocks.read_only_allow_delete\": null}. Or for all indices: PUT /_settings {\"index.blocks.read_only_allow_delete\": null}. Verify with: GET /_cat/allocation?v to check disk usage per node.",
      "sources": [],
      "condition": ""
    },
    {
      "action": "Adjust the disk watermark thresholds if the defaults are too aggressive for your setup",
      "success_rate": 0.85,
      "how": "Update cluster settings: PUT /_cluster/settings {\"persistent\": {\"cluster.routing.allocation.disk.watermark.flood_stage\": \"97%\", \"cluster.routing.allocation.disk.watermark.high\": \"95%\", \"cluster.routing.allocation.disk.watermark.low\": \"90%\"}}. Only increase these if you have monitoring in place and understand the risk of running at high disk utilization. This is a temporary measure while scaling storage.",
      "sources": [],
      "condition": ""
    }
  ],
  "transition_graph": {
    "leads_to": [
      {"error_id": "database/disk-full/pg16-linux", "probability": 0.10, "condition": "when the same server hosts both Elasticsearch and PostgreSQL, and disk space issues affect both"}
    ],
    "preceded_by": [
      {"error_id": "database/redis-oom/redis7-linux", "probability": 0.05, "condition": "when Redis OOM dumps data to disk, consuming space that pushes Elasticsearch past the flood stage"}
    ],
    "frequently_confused_with": [
      {"error_id": "database/redis-readonly/redis7-linux", "distinction": "Elasticsearch read-only is triggered by disk space watermarks as a protective measure. Redis READONLY is triggered by replication (writes to a replica) or explicit configuration. Both prevent writes but for completely different reasons."}
    ]
  },
  "metadata": {
    "generated_by": "bulk_generate.py",
    "generation_date": "2026-02-12",
    "review_status": "auto_generated",
    "evidence_count": 55,
    "last_verification": "2026-02-12"
  }
}
