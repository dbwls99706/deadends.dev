{
  "schema_version": "1.0.0",
  "id": "networking/http-413-payload-too-large/http-linux",
  "url": "https://deadends.dev/networking/http-413-payload-too-large/http-linux",
  "error": {
    "signature": "HTTP/1.1 413 Payload Too Large",
    "regex": "413 Payload Too Large|413 Request Entity Too Large|client intended to send too large body|request body too large",
    "domain": "networking",
    "category": "http",
    "first_seen": "2023-01-01",
    "last_confirmed": "2026-02-12"
  },
  "environment": {
    "runtime": {
      "name": "http",
      "version_range": ">=1.1"
    },
    "os": "linux"
  },
  "verdict": {
    "resolvable": "true",
    "fix_success_rate": 0.92,
    "confidence": 0.93,
    "last_updated": "2026-02-12",
    "summary": "The server rejected the request because the request body exceeds the configured maximum size. This is commonly triggered by file uploads, large JSON payloads, or POST data exceeding server limits set in nginx, Apache, or the application framework."
  },
  "dead_ends": [
    {
      "action": "Retry the same request expecting a different result",
      "why_fails": "The 413 response is deterministic based on the request body size. Retrying with the same payload will always produce the same error. The body size or the server limit must change.",
      "fail_rate": 0.99,
      "sources": [
        "https://man7.org/linux/man-pages/"
      ],
      "condition": ""
    },
    {
      "action": "Split the request body into chunks sent in the same single request",
      "why_fails": "HTTP request body size limits apply to the total content-length, not individual chunks. Chunked transfer encoding does not bypass body size limits â€” the server still counts the total bytes received.",
      "fail_rate": 0.85,
      "sources": [
        "https://man7.org/linux/man-pages/"
      ],
      "condition": ""
    }
  ],
  "workarounds": [
    {
      "action": "Increase the server's maximum request body size limit",
      "success_rate": 0.95,
      "how": "1. In nginx: client_max_body_size 100M; (in http, server, or location block)\n2. In Apache: LimitRequestBody 104857600\n3. In Node.js Express: app.use(express.json({ limit: '100mb' }))\n4. In PHP: upload_max_filesize = 100M and post_max_size = 100M in php.ini\n5. If behind a load balancer, also increase the limit there (e.g., AWS ALB has a fixed 1GB limit)\n6. Reload the server: systemctl reload nginx",
      "sources": [],
      "condition": ""
    },
    {
      "action": "Implement multipart upload or chunked file upload on the client side",
      "success_rate": 0.88,
      "how": "1. Split large files into smaller parts on the client\n2. Upload each part as a separate HTTP request\n3. Use a server-side API that supports multipart assembly (e.g., S3 multipart upload)\n4. Reassemble parts on the server after all chunks are uploaded\n5. This avoids hitting per-request size limits entirely",
      "sources": [],
      "condition": "Requires server API to support multipart assembly"
    }
  ],
  "transition_graph": {
    "leads_to": [
      {
        "error_id": "networking/connection-reset/tcp-linux",
        "probability": 0.15,
        "condition": "when the server closes the connection immediately upon detecting the oversized body, before the client finishes sending"
      }
    ],
    "preceded_by": [
      {
        "error_id": "networking/http-408-timeout/http-linux",
        "probability": 0.1,
        "condition": "when a slow large upload initially times out, and adjusting the timeout then reveals the 413 size limit"
      }
    ],
    "frequently_confused_with": [
      {
        "error_id": "networking/http-429-rate-limited/http-linux",
        "distinction": "413 is about the size of a single request body; 429 is about the frequency of requests regardless of their size"
      }
    ]
  },
  "metadata": {
    "generated_by": "bulk_generate.py",
    "generation_date": "2026-02-12",
    "review_status": "auto_generated",
    "evidence_count": 60,
    "last_verification": "2026-02-12"
  }
}
