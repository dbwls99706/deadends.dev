{
  "schema_version": "1.0.0",
  "id": "python/cuda-out-of-memory/torch2.1-rtx3090",
  "url": "https://deadends.dev/python/cuda-out-of-memory/torch2.1-rtx3090",
  "error": {
    "signature": "RuntimeError: CUDA out of memory. Tried to allocate X GiB",
    "regex": "RuntimeError: CUDA out of memory\\. Tried to allocate \\d+\\.\\d+ [GM]iB",
    "domain": "python",
    "category": "resource_exhaustion",
    "first_seen": "2020-03-15",
    "last_confirmed": "2025-04-10"
  },
  "environment": {
    "runtime": {
      "name": "pytorch",
      "version_range": ">=2.0,<2.3"
    },
    "hardware": {
      "gpu": "RTX-3090",
      "vram_gb": 24
    },
    "os": "linux",
    "python": ">=3.9,<3.13",
    "additional": {}
  },
  "verdict": {
    "resolvable": "partial",
    "fix_success_rate": 0.28,
    "confidence": 0.75,
    "last_updated": "2025-04-10",
    "summary": "RTX 3090 has 24GB VRAM \u2014 significantly less than A100-40GB. Models above 7B parameters in FP16 will frequently OOM. batch_size reduction has lower success rate here due to tighter memory margins."
  },
  "dead_ends": [
    {
      "action": "Calling torch.cuda.empty_cache()",
      "why_fails": "Does not resolve memory fragmentation. Space occupied by already-allocated tensors is not freed.",
      "fail_rate": 0.91,
      "sources": [
        "https://github.com/pytorch/pytorch/issues/16417"
      ],
      "common_misconception": "empty_cache only returns cached unused blocks \u2014 no effect on active tensors."
    },
    {
      "action": "Reducing batch_size to 1",
      "why_fails": "With only 24GB VRAM, models above 7B parameters exceed memory even at batch_size=1 in FP16. 7B model ~14GB params + optimizer states + activations > 24GB.",
      "fail_rate": 0.68,
      "condition": "model_params >= 7B",
      "sources": [
        "https://pytorch.org/docs/stable/notes/cuda.html#memory-management"
      ]
    },
    {
      "action": "Using torch.compile() for memory optimization",
      "why_fails": "torch.compile() actually increases peak memory usage during compilation. On memory-constrained GPUs like RTX 3090, this makes OOM worse, not better.",
      "fail_rate": 0.78,
      "sources": [
        "https://github.com/pytorch/pytorch/issues/97358"
      ]
    }
  ],
  "workarounds": [
    {
      "action": "Enable gradient_checkpointing",
      "how": "model.gradient_checkpointing_enable()",
      "success_rate": 0.65,
      "tradeoff": "Training speed decreases by 20-30%",
      "condition": "Model must support gradient_checkpointing",
      "sources": [
        "https://huggingface.co/docs/transformers/perf_train_gpu_one"
      ]
    },
    {
      "action": "Use 4-bit quantization with bitsandbytes",
      "how": "model = AutoModelForCausalLM.from_pretrained(name, load_in_4bit=True)",
      "success_rate": 0.78,
      "tradeoff": "Quality degradation in some tasks; requires bitsandbytes library",
      "condition": "bitsandbytes must be installed; model must be compatible with quantization",
      "sources": [
        "https://huggingface.co/docs/transformers/quantization"
      ]
    },
    {
      "action": "Switch to mixed precision (FP16/BF16)",
      "how": "torch.cuda.amp.autocast() or Trainer(fp16=True)",
      "success_rate": 0.45,
      "tradeoff": "RTX 3090 supports BF16 but with lower throughput than A100. Numerical instability possible.",
      "condition": "Model must be FP16-stable",
      "sources": [
        "https://pytorch.org/docs/stable/amp.html"
      ]
    }
  ],
  "transition_graph": {
    "leads_to": [],
    "preceded_by": [],
    "frequently_confused_with": []
  },
  "metadata": {
    "generated_by": "deadend-seed-v1",
    "generation_date": "2025-06-01",
    "review_status": "auto_generated",
    "evidence_count": 38,
    "page_views": 0,
    "ai_agent_hits": 0,
    "human_hits": 0,
    "last_verification": "2025-06-01"
  }
}
