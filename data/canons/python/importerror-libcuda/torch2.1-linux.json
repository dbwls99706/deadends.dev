{
  "schema_version": "1.0.0",
  "id": "python/importerror-libcuda/torch2.1-linux",
  "url": "https://deadend.dev/python/importerror-libcuda/torch2.1-linux",

  "error": {
    "signature": "ImportError: libcuda.so.1: cannot open shared object file: No such file or directory",
    "regex": "ImportError: libcuda\\.so\\.1: cannot open shared object file: No such file or directory",
    "domain": "python",
    "category": "native_dependency_error",
    "first_seen": "2019-03-01",
    "last_confirmed": "2025-05-19"
  },

  "environment": {
    "runtime": { "name": "pytorch", "version_range": ">=2.0,<2.3" },
    "os": "linux",
    "python": ">=3.9,<3.13",
    "additional": {
      "common_contexts": ["Docker containers without GPU passthrough", "headless servers", "WSL2 without CUDA driver"]
    }
  },

  "verdict": {
    "resolvable": "true",
    "fix_success_rate": 0.79,
    "confidence": 0.83,
    "last_updated": "2025-05-19",
    "summary": "libcuda.so.1 is provided by the NVIDIA GPU driver (not the CUDA toolkit). This error means the driver is either not installed, not accessible (common in containers), or the library path is not configured. On systems with an NVIDIA GPU and driver installed, setting LD_LIBRARY_PATH or creating the proper symlink resolves the issue. In Docker, nvidia-container-toolkit must be configured."
  },

  "dead_ends": [
    {
      "action": "Running 'pip install cuda' or 'pip install nvidia-cuda-runtime'",
      "why_fails": "libcuda.so.1 is part of the NVIDIA GPU driver, not the CUDA toolkit or any pip-installable package. The GPU driver is a kernel module and userspace library installed at the OS level. No pip package can provide it because it must match the exact kernel module version loaded on the system.",
      "fail_rate": 0.98,
      "sources": ["https://docs.nvidia.com/cuda/cuda-installation-guide-linux/"],
      "common_misconception": "Users conflate the CUDA toolkit (nvcc, cuBLAS, cuDNN) with the CUDA driver (libcuda.so). The driver is provided by the NVIDIA display driver package, not by any CUDA SDK or pip package."
    },
    {
      "action": "Running 'apt-get install nvidia-driver-xxx' inside a Docker container",
      "why_fails": "GPU drivers cannot be installed inside containers. The driver runs at the host kernel level. Containers access the GPU through the NVIDIA Container Toolkit (nvidia-docker2 / nvidia-container-toolkit), which bind-mounts the host's driver libraries into the container at runtime.",
      "fail_rate": 0.92,
      "condition": "Running inside a Docker container",
      "sources": ["https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/overview.html"],
      "common_misconception": "Users try to install the full NVIDIA driver stack inside a container, but the driver is a host-level component."
    },
    {
      "action": "Installing cuda-toolkit without the driver component",
      "why_fails": "The CUDA toolkit (installed via apt or runfile) includes development tools (nvcc) and libraries (cuBLAS, cuDNN) but does not always include the driver. When using the network repository, 'apt install cuda-toolkit-12-x' specifically excludes the driver. libcuda.so.1 is in the 'cuda-drivers' or 'nvidia-driver-xxx' package.",
      "fail_rate": 0.75,
      "sources": ["https://developer.nvidia.com/cuda-downloads"]
    }
  ],

  "workarounds": [
    {
      "action": "Set LD_LIBRARY_PATH to include the NVIDIA driver library directory",
      "how": "The driver library is typically at /usr/lib/x86_64-linux-gnu/ or /usr/local/cuda/lib64/ or /usr/lib64/. Run 'find / -name libcuda.so.1 2>/dev/null' to locate it, then 'export LD_LIBRARY_PATH=/path/to/dir:$LD_LIBRARY_PATH'. Add to .bashrc for persistence.",
      "success_rate": 0.82,
      "tradeoff": "Only works if the driver is already installed but not on the default library path",
      "sources": ["https://docs.nvidia.com/cuda/cuda-installation-guide-linux/#post-installation-actions"]
    },
    {
      "action": "Install the NVIDIA driver on the host system",
      "how": "On Ubuntu/Debian: 'sudo apt update && sudo apt install nvidia-driver-535' (or latest version). On RHEL/CentOS: use the NVIDIA CUDA repository. Verify with 'nvidia-smi'. Reboot after installation.",
      "success_rate": 0.88,
      "tradeoff": "Requires root access and a system reboot. Driver version must be compatible with the installed CUDA toolkit version.",
      "condition": "System must have a physical NVIDIA GPU",
      "sources": ["https://docs.nvidia.com/cuda/cuda-installation-guide-linux/"]
    },
    {
      "action": "Configure NVIDIA Container Toolkit for Docker",
      "how": "On the host: install nvidia-container-toolkit ('apt install nvidia-container-toolkit'), configure Docker runtime ('nvidia-ctk runtime configure --runtime=docker && systemctl restart docker'), then run containers with '--gpus all' flag: 'docker run --gpus all myimage'.",
      "success_rate": 0.85,
      "tradeoff": "Adds infrastructure dependency. Requires NVIDIA driver on host and nvidia-container-toolkit package.",
      "condition": "Applicable when running PyTorch inside Docker containers",
      "sources": ["https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html"]
    }
  ],

  "transition_graph": {
    "leads_to": [
      {
        "error_id": "python/cuda-version-mismatch/torch2.1-linux",
        "probability": 0.30,
        "condition": "After installing the driver, the driver CUDA version may not match PyTorch's expected CUDA version",
        "typical_delay": "immediate"
      },
      {
        "error_id": "python/cuda-out-of-memory/torch2.1-a100-40gb",
        "probability": 0.10,
        "condition": "After fixing the driver issue, the GPU may have insufficient memory for the workload",
        "typical_delay": "minutes"
      }
    ],
    "preceded_by": [
      {
        "error_id": "python/pip-install-torch-cpu-only/torch2.1-linux",
        "probability": 0.25,
        "condition": "User installed CPU-only PyTorch then switched to GPU code"
      }
    ],
    "frequently_confused_with": [
      {
        "error_id": "python/importerror-libcudart/torch2.1-linux",
        "distinction": "libcuda.so.1 is from the NVIDIA driver. libcudart.so is from the CUDA toolkit runtime. Missing libcuda means no driver; missing libcudart means the CUDA toolkit is not installed or not on the path."
      }
    ]
  },

  "metadata": {
    "generated_by": "deadend-seed-v1",
    "generation_date": "2025-06-01",
    "review_status": "auto_generated",
    "evidence_count": 56,
    "page_views": 0,
    "ai_agent_hits": 0,
    "human_hits": 0,
    "last_verification": "2025-06-01"
  }
}
